{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from numpy.core.umath_tests import matrix_multiply as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    return pd.read_csv(file,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random(col):\n",
    "    minval = col.min()\n",
    "    maxval = col.max()\n",
    "\n",
    "    # Generate a random number from a uniform distribution of the min and max of the column.\n",
    "    return np.random.uniform(minval,maxval,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_Algorithm(iris, k, e):\n",
    "    \n",
    "    n = len(iris)\n",
    "    \n",
    "    # E-Step\n",
    "    \n",
    "    # Init values\n",
    "    \n",
    "    sigma = np.array([np.eye(4)] * k)\n",
    "    \n",
    "    cl_mu = []\n",
    "    cl_p = []\n",
    "    for i in range(k):\n",
    "        atr_mu = []\n",
    "        for col in iris[[0,1,2,3]]:\n",
    "            atr_mu.append(gen_random(iris[col]))\n",
    "        cl_mu.append(atr_mu)\n",
    "        cl_p.append(1/k)\n",
    "    \n",
    "    cl_mus = np.array(cl_mu)\n",
    "    \n",
    "    \n",
    "    like_old = 0\n",
    "    i = 0\n",
    "    diff = 1\n",
    "    \n",
    "    while diff > e and i < 1000000:\n",
    "            ws = np.zeros((k, n))\n",
    "            \n",
    "            # for each cluster calculate the probability\n",
    "            for j in range(k):\n",
    "                ws[j, :] = cl_p[j] * mvn(cl_mus[j], sigma[j]).pdf(iris.loc[:,0:3])\n",
    "            ws /= ws.sum(0)\n",
    "            \n",
    "            \n",
    "            # M Step\n",
    "            \n",
    "            # update probabilities\n",
    "            cl_p = ws.sum(axis=1)\n",
    "            cl_p /= n\n",
    "            \n",
    "            cl_mus = np.dot(ws, iris.loc[:,0:3])\n",
    "            cl_mus /= ws.sum(1)[:, None]\n",
    "\n",
    "            #print(mus)\n",
    "            # update sigmas\n",
    "            sigma = np.zeros((k, 4, 4))\n",
    "\n",
    "            for j in range(k):\n",
    "                # get values from data frame, subtract mean values and convert to numpy array\n",
    "                ys = (iris.loc[:,0:3] - cl_mus[j, :]).to_numpy()\n",
    "\n",
    "                # Calculate sigmas\n",
    "                sigma[j] = (ws[j, :, None, None] * mm(ys[:, :, None], ys[:, None, :])).sum(axis=0)\n",
    "            sigma /= ws.sum(axis=1)[:, None, None]\n",
    "\n",
    "            # init temporary log likelihood variable\n",
    "            like_new = 0\n",
    "        \n",
    "            # caclulate probability for each\n",
    "            for p, mu, sig in zip(cl_p, cl_mus, sigma):\n",
    "                like_new += p * mvn(mu, sig).pdf(iris.loc[:,0:3].to_numpy())\n",
    "\n",
    "            like_new = np.log(like_new).sum()\n",
    "\n",
    "            diff = np.abs(like_new - like_old)\n",
    "            like_old = like_new\n",
    "\n",
    "            # increment counter\n",
    "            i += 1\n",
    "    \n",
    "    print(\"\\n Number of iterations for the convergence is = \", i)\n",
    "    new_nodes = pd.DataFrame()\n",
    "    for node, point in enumerate(ws):\n",
    "        new_nodes[node] = point\n",
    "    \n",
    "    new_nodes['tag'] = new_nodes.idxmax(axis=1)\n",
    "    print(\"\\n The number of nodes in new clusters are - \\n\", new_nodes.groupby(['tag']).agg('count')[0])\n",
    "    \n",
    "    print(\"\\n Mean Matrix for the 3 clusters is - \\n\", cl_mus)\n",
    "    \n",
    "    print(\"\\n Covariance for the 3 clusters are - \\n\", sigma)\n",
    "    \n",
    "    return diff, like_new, cl_p, cl_mus, sigma, i, ws\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of iterations for the convergence is =  25\n",
      "\n",
      " The number of nodes in new clusters are - \n",
      " tag\n",
      "0    50\n",
      "1    51\n",
      "2    49\n",
      "Name: 0, dtype: int64\n",
      "\n",
      " Mean Matrix for the 3 clusters is - \n",
      " [[5.00622574 3.41849879 1.46407274 0.2439742 ]\n",
      " [6.28644387 2.78225055 4.67362944 1.4481268 ]\n",
      " [6.23867405 2.95461529 5.11897605 1.88578571]]\n",
      "\n",
      " Covariance for the 3 clusters are - \n",
      " [[[0.12170433 0.09808362 0.01578603 0.01035326]\n",
      "  [0.09808362 0.14178197 0.01137131 0.01124095]\n",
      "  [0.01578603 0.01137131 0.02950515 0.00559047]\n",
      "  [0.01035326 0.01124095 0.00559047 0.01126738]]\n",
      "\n",
      " [[0.60718492 0.18087948 0.71191297 0.22103544]\n",
      "  [0.18087948 0.1422663  0.18602168 0.06866512]\n",
      "  [0.71191297 0.18602168 0.98339189 0.30827955]\n",
      "  [0.22103544 0.06866512 0.30827955 0.10715259]]\n",
      "\n",
      " [[0.27600154 0.0699252  0.21869407 0.12521287]\n",
      "  [0.0699252  0.0653043  0.06411204 0.05306872]\n",
      "  [0.21869407 0.06411204 0.29993333 0.17357957]\n",
      "  [0.12521287 0.05306872 0.17357957 0.15339671]]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   \n",
    "    filename = 'iris.txt'\n",
    "    clusters = 3\n",
    "    epsilon = 0.001\n",
    "    \n",
    "    # Read the text file\n",
    "    df = read_data(filename)\n",
    "    \n",
    "    # Apply EM algorithm\n",
    "    eps, ll2, Ps, means, covs, iterations, points = EM_Algorithm(df, clusters, epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
